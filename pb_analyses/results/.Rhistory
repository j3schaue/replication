source("./misc.R")
paper = 'rand'
tes = 'd'; vr = 'vd'
###------------------------------------------------------------###
###------------------------------------------------------------###
### Rand Comparison
###------------------------------------------------------------###
###------------------------------------------------------------###
# load the data
data = read.csv("../data/rrr_rand.csv") %>%
filter(is.finite(d)) %>%   # weed out infinite estimates
filter(!is.na(d))
experiments = unique(data$experiment)
df_inc = do.call(rbind,
lapply(experiments, FUN=function(exp){
dd = dplyr::filter(data, experiment==exp)
ff = rma.uni(dd[[tes]], dd[[vr]], method='FE')
dd$student = rstudent(ff)$z
dd$standard = rstandard(ff)$z
dd$Qi = leave1out(ff)$Q
dd$tbardot = rep(ff$beta, nrow(dd))
return(dd)
})
)
randoutliers = df_inc %>% group_by(experiment) %>% filter(abs(standard) > 2) %>% count()
###------------------------------------------------------------###
###------------------------------------------------------------###
###------------------------------------------------------------###
### ANALYSES OF RRR:WAGENMAKERS REPLICATION ANALYSES
###------------------------------------------------------------###
###------------------------------------------------------------###
###------------------------------------------------------------###
# set the working directory to src so we can use relative paths
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(dplyr); library(metafor)
source("../package/replicationTest.R")
source("../package/mdh.R")
source("./misc.R")
paper = 'wagenmakers'
tes = 'd'; vr = 'vd'
###------------------------------------------------------------###
###------------------------------------------------------------###
### Wagenmakers Comparison
###------------------------------------------------------------###
###------------------------------------------------------------###
# load the data
data = read.csv("../data/rrr_wagenmakers.csv") %>%
filter(is.finite(d)) %>%   # weed out infinite estimates
filter(!is.na(d))
experiments = unique(data$experiment)
df_inc = do.call(rbind,
lapply(experiments, FUN=function(exp){
dd = dplyr::filter(data, experiment==exp)
ff = rma.uni(dd[[tes]], dd[[vr]], method='FE')
dd$student = rstudent(ff)$z
dd$standard = rstandard(ff)$z
dd$Qi = leave1out(ff)$Q
dd$tbardot = rep(ff$beta, nrow(dd))
return(dd)
})
)
wagenoutliers = df_inc %>% group_by(experiment) %>% filter(abs(standard) > 2) %>% count()
###------------------------------------------------------------###
###------------------------------------------------------------###
###------------------------------------------------------------###
### ANALYSES OF PPIR REPLICATIONS
###------------------------------------------------------------###
###------------------------------------------------------------###
###------------------------------------------------------------###
# set the working directory to src so we can use relative paths
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(dplyr); library(metafor)
source("../package/replicationTest.R")
source("../package/mdh.R")
source("./misc.R")
paper = 'ppir'
tes = 'd'; vr = 'vd'
# load the data
data = read.csv("../data/ppir.csv") %>%
filter(is.finite(d)) %>%   # weed out infinite estimates
filter(!is.na(d))
experiments = unique(data$experiment)
df_inc = do.call(rbind,
lapply(experiments, FUN=function(exp){
dd = dplyr::filter(data, experiment==exp)
ff = rma.uni(dd[[tes]], dd[[vr]], method='FE')
dd$student = rstudent(ff)$z
dd$standard = rstandard(ff)$z
dd$Qi = leave1out(ff)$Q
dd$tbardot = rep(ff$beta, nrow(dd))
return(dd)
})
)
ppiroutliers = df_inc %>% group_by(experiment) %>% filter(abs(standard) > 2) %>% count()
ppiroutliers
mliroutliers
mloutliers
algonaoutliers
algonoutliers
alignaoutliers
alognaoutliers
cheungoutliers
eerlandoutliers
haggeroutliers
wagenoutliers
randoutliers
summary(dol$stdresid)
summary(abs(dol$stdresid))
###------------------------------------------------------------###
###------------------------------------------------------------###
###------------------------------------------------------------###
### ANALYSES OF MANYLABS REPLICATIONS
###------------------------------------------------------------###
###------------------------------------------------------------###
###------------------------------------------------------------###
# set the working directory to src so we can use relative paths
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(dplyr); library(metafor)
source("../package/replicationTest.R")
source("../package/mdh.R")
source("./misc.R")
paper = 'manylabs'
tes = 't'; vr = 'v'
###------------------------------------------------------------###
###------------------------------------------------------------###
### Many Labs Comparison
###------------------------------------------------------------###
###------------------------------------------------------------###
# load the data
data = read.csv("../data/manylabs_d.csv") %>%
filter(is.finite(t)) %>%   # weed out infinite estimates
filter(!is.na(t))
experiments = unique(data$experiment)
df_inc = do.call(rbind,
lapply(experiments, FUN=function(exp){
dd = dplyr::filter(data, experiment==exp)
ff = rma.uni(dd$t, dd$v, method='FE')
dd$student = rstudent(ff)$z
dd$standard = rstandard(ff)$z
dd$Qi = leave1out(ff)$Q
dd$tbardot = rep(ff$beta, nrow(dd))
if('original' %in% dd$site){
return(dd)
} else {
foo = data.frame(matrix(rep(NA, ncol(dd)), ncol=ncol(dd)))
names(foo) = names(dd)
return(foo)
}
})
) %>% filter(!is.na(experiment)) %>% filter(!is.na(t))
df_inc %>% filter(grepl('Anchor', experiment))
df_inc %>% filter(grepl('Anchor', experiment)) %>% filter(abs(standard) > 2)
df_inc %>% filter(grepl('Anchor', experiment)) %>% filter(abs(standard) > 2) %>% select(experiment, site, standard)
mloutliers
sdn
dsen
sen
# set the working directory to src so we can use relative paths
setwd(paste0(dirname(rstudioapi::getActiveDocumentContext()$path), "/results"))
library(dplyr)
source("../misc.R")
###-----------------------------------------------------------------------------###
###-----------------------------------------------------------------------------###
###-----------------------------------------------------------------------------###
### COMPARISON ANALYSES
### Analyses for k=2 comparisons of replication
### Read in analyses on the scale of Cohen's d and
### other scales to check robustness.
###-----------------------------------------------------------------------------###
###-----------------------------------------------------------------------------###
###-----------------------------------------------------------------------------###
#------Check if conversion to Cohen's d affects decisions
# alogna et al
al = read.csv("./comparison_alogna_FE.csv") %>% mutate(es='rd')
ald = read.csv("./comparison_alogna_FE_d.csv") %>% mutate(es='d')
# many labs
ml = read.csv("./comparison_manylabs_FE.csv") %>%
filter(experiment %in% c("Allowedforbidden", "Gainloss", "IAT", "Scales")) %>%
mutate(es = c('logor', 'logor', 'z', 'rd'))
mld = read.csv("./comparison_manylabs_FE_d.csv") %>%
filter(experiment %in% c("Allowedforbidden", "Gainloss", "IAT", "Scales")) %>%
mutate(es='d')
# RPP
rpp = read.csv("./comparison_rpp_FE.csv") %>% mutate(es='z')
rppd = read.csv("./comparison_rpp_FE_d.csv") %>% mutate(es='d')
# RPE
rpe = read.csv("./comparison_rpe_FE.csv") %>% mutate(es='z')
rped = read.csv("./comparison_rpe_FE_d.csv") %>% mutate(es='d')
tocheck = list(alogna=list(al, ald), manylabs=list(ml, mld), rpp=list(rpp, rppd), rpe=list(rpe, rped))
for(i in seq(tocheck)){
print(names(tocheck)[i])
print(which(as.integer(tocheck[[i]][[1]]$p0 < .05) != as.integer(tocheck[[i]][[2]]$p0 < .05)))
print(which(as.integer(tocheck[[i]][[1]]$p25 < .05) != as.integer(tocheck[[i]][[2]]$p25 < .05)))
print(which(as.integer(tocheck[[i]][[1]]$p33 < .05) != as.integer(tocheck[[i]][[2]]$p33 < .05)))
print(which(as.integer(tocheck[[i]][[1]]$p67 < .05) != as.integer(tocheck[[i]][[2]]$p67 < .05)))
print(summary(tocheck[[i]][[1]]$p0 - tocheck[[i]][[2]]$p0))
print(summary(tocheck[[i]][[1]]$p25 - tocheck[[i]][[2]]$p25))
print(summary(tocheck[[i]][[1]]$p33 - tocheck[[i]][[2]]$p33))
print(summary(tocheck[[i]][[1]]$p67 - tocheck[[i]][[2]]$p67))
}
# For Alogna et al, there are no differences between conclusions, and p-values differ by less than .02, and on average by .015.
# Notably for Alogna, all of the (d) p-values are larger than the risk difference p-values
# For Many Labs, there are no differences in conclusions. The largest difference in p-values is 0.03. In fact, the only different
# p-value is for the IAT experiment which was initially on the scale of the z transform. All p-values are about 0.03 larger
# for the z scale.
# For RPP, there is one experiment that comes to a different conclusion for p25 and p33: E Nurmsoo. It's a small study, and the
# p-values tend to be larger for the z scale.
# There are some larger differences in p-values, but this is largely for smaller studies.
# For RPE, there are no qualitative differences. p-values are all within .02 of each other.
###------------Cohen's d scale analysis
dtoload = grep("(alogna|manylabs|rpe|rpp)_FE.csv", grep("comparison_.*_FE", list.files(), value=T), value=T, invert=T)
ddfs = lapply(dtoload, FUN=function(ff){
print(ff)
foo = read.csv(ff)
foo = foo %>%
dplyr::select(paper, experiment, k, Q, calpha0, p0, mdh0, calpha25,
p25, mdh25, calpha33, p33, mdh33, calpha67, p67,
mdh67, replicated, t1, t2, v1, v2) %>%
filter(!is.na(Q)) %>%
mutate(mdh0scale = sqrt(mdh0 * (v1 + v2)), # MDH on the scale of absolute differences
mdh25scale = sqrt(mdh25 * (v1 + v2)),
mdh33scale = sqrt(mdh33 * (v1 + v2)),
mdh67scale = sqrt(mdh67 * (v1 + v2)))
return(foo)
})
dft = do.call(rbind, ddfs)
write.csv(dft, './aggregate/full_comparison_d.csv', row.names=F)
##----aggregate by paper
# group all registered replication reports
rrrs = c('alogna', 'cheung', 'eerland', 'hagger', 'rand', 'wagenmakers')
daggrrr = dft %>% filter(paper %in% rrrs) %>%
summarize(nstudies = n(),
nonreplication = sum(replicated == 0),
nonrep0 = sum(p0 < .05), # original nonreplication determinations
nonrep25 = sum(p25 < .05), # nonreplications according to Q test
nonrep33 = sum(p33 < .05),
nonrep67 = sum(p67 < .05),
mdh0scale = mean(mdh0scale), # MDH on the scale of absolute differences
mdh25scale = mean(mdh25scale),
mdh33scale = mean(mdh33scale),
mdh67scale = mean(mdh67scale)) %>%
cbind(data.frame(paper = 'rrr'), .)
dagg1 = dft %>% filter(!(paper %in% rrrs)) %>% group_by(paper) %>%
summarize(nstudies = n(),
nonreplication = sum(replicated == 0),
nonrep0 = sum(p0 < .05), # original nonreplication determinations
nonrep25 = sum(p25 < .05), # nonreplications according to Q test
nonrep33 = sum(p33 < .05),
nonrep67 = sum(p67 < .05),
mdh0scale = mean(mdh0scale), # MDH on the scale of absolute differences
mdh25scale = mean(mdh25scale),
mdh33scale = mean(mdh33scale),
mdh67scale = mean(mdh67scale))
dagg = rbind(daggrrr, dagg1)
dagg
write.csv(dagg, "./aggregate/table2d.csv", row.names=F)
##----get most powerful studies
sen = dft %>% filter(mdh0scale <= .3)
sen
write.csv(sen, "./aggregate/send.csv", row.names=F)
# Only 3 studies are powered to detect anything on the oder of an absolute difference smaller than d = .3
# Two are Many Labs studies where the initial variance is quite small (v1 = .0025 for both Allowed/Forbidden and Reciprocity)
# One is an RPP where v1 = .007 and v2 = .001.
# for what it's worth that's about 1000 people per arm!
###-----Comparison analysis with raw effect sizes-------------------
# Mostly checking results above
toload = grep("(alogna|manylabs|rpe|rpp)_FE_d.csv", grep("comparison_.*_FE", list.files(), value=T), value=T, invert=T)
dfs = lapply(toload, FUN=function(ff){
print(ff)
foo = read.csv(ff)
foo = foo %>%
dplyr::select(paper, experiment, k, Q, calpha0, p0, mdh0, calpha25,
p25, mdh25, calpha33, p33, mdh33, calpha67, p67,
mdh67, replicated, t1, t2, v1, v2) %>%
filter(!is.na(Q)) %>%
mutate(mdh0scale = sqrt(mdh0 * (v1 + v2)), # MDH on the scale of absolute differences
mdh25scale = sqrt(mdh25 * (v1 + v2)),
mdh33scale = sqrt(mdh33 * (v1 + v2)),
mdh67scale = sqrt(mdh67 * (v1 + v2)))
return(foo)
})
ft = do.call(rbind, dfs)
write.csv(ft, './aggregate/full_comparison.csv', row.names=F)
##----aggregate by paper
# group all registered replication reports
aggrrr = ft %>% filter(paper %in% rrrs) %>%
summarize(nstudies = n(),
nonreplication = sum(replicated == 0),
nonrep0 = sum(p0 < .05), # original nonreplication determinations
nonrep25 = sum(p25 < .05), # nonreplications according to Q test
nonrep33 = sum(p33 < .05),
nonrep67 = sum(p67 < .05),
mdh0scale = mean(mdh0scale), # MDH on the scale of absolute differences
mdh25scale = mean(mdh25scale),
mdh33scale = mean(mdh33scale),
mdh67scale = mean(mdh67scale)) %>%
cbind(data.frame(paper = 'rrr'), .)
agg1 = ft %>% filter(!(paper %in% rrrs)) %>% group_by(paper) %>%
summarize(nstudies = n(),
nonreplication = sum(replicated == 0),
nonrep0 = sum(p0 < .05), # original nonreplication determinations
nonrep25 = sum(p25 < .05), # nonreplications according to Q test
nonrep33 = sum(p33 < .05),
nonrep67 = sum(p67 < .05),
mdh0scale = mean(mdh0scale), # MDH on the scale of absolute differences
mdh25scale = mean(mdh25scale),
mdh33scale = mean(mdh33scale),
mdh67scale = mean(mdh67scale))
agg = rbind(aggrrr, agg1)
agg
dagg # confirmed it's only the one RPP experiment that has a few different conclusions.
write.csv(agg, './aggregate/table2.csv', row.names=F)
###-----------------------------------------------------------------------------###
###-----------------------------------------------------------------------------###
###-----------------------------------------------------------------------------###
### Q-test Results
###-----------------------------------------------------------------------------###
###-----------------------------------------------------------------------------###
###-----------------------------------------------------------------------------###
###-------------INCLUDE INITIAL FINDING---------------------------------###
###--------Cohen's d Scale
dtoloadq = grep("outlier", #drop outlier files
grep("(alogna|manylabs)_include.csv", # only include the _d files for algona/manylabs
grep("qtest_fixed_.*_include", list.files(), value=T),
value=T, invert=T),
value=T, invert=T)
dqs = do.call(rbind, lapply(dtoloadq, read.csv)) %>%
mutate(mdh0scale = sqrt(2 * vbar * mdh0),
mdh25scale = sqrt(2 * vbar * mdh25),
mdh33scale = sqrt(2 * vbar * mdh33),
mdh67scale = sqrt(2 * vbar * mdh67))
dqs
dqs %>% group_by(paper) %>% summarize(mdh0 = mean(mdh0scale),
mdh25 = mean(mdh25scale),
mdh33 = mean(mdh33scale),
mdh67 = mean(mdh67scale))
write.csv(dqs, "./aggregate/qtest_include_full_d.csv", row.names=F)
write.csv(dqs %>% select(paper, experiment, k, Q, replicated, p0, p25, p33, p67, mdh0scale, mdh25scale, mdh33scale, mdh67scale),
"./aggregate/table3d.csv")
###--------Natural Scale
toloadq = grep("outlier", #drop outlier files
grep("(alogna|manylabs)_include_d.csv", # only include the _d files for algona/manylabs
grep("qtest_fixed_.*_include", list.files(), value=T),
value=T, invert=T),
value=T, invert=T)
qs = do.call(rbind, lapply(toloadq, read.csv)) %>%
mutate(mdh0scale = sqrt(2 * vbar * mdh0),
mdh25scale = sqrt(2 * vbar * mdh25),
mdh33scale = sqrt(2 * vbar * mdh33),
mdh67scale = sqrt(2 * vbar * mdh67))
qs
write.csv(qs, "./aggregate/qtest_include_full.csv", row.names=F)
###----Compare scales
# qs$experiment == dqs$experiment
sum(as.integer(qs$p0 < .05) != as.integer(dqs$p0 < .05))
sum(as.integer(qs$p25 < .05) != as.integer(dqs$p25 < .05))
sum(as.integer(qs$p33 < .05) != as.integer(dqs$p33 < .05))
sum(as.integer(qs$p67 < .05) != as.integer(dqs$p67 < .05))
summary(abs(qs$p0 - dqs$p0))
summary(abs(qs$p25 - dqs$p25))
summary(abs(qs$p33 - dqs$p33))
summary(abs(qs$p67 - dqs$p67))
# p-values are pretty close to the same. Only a few have a difference large enough to care about, but they don't affect conclusions.
###-------------EXCLUDE INITIAL FINDING---------------------------------###
###--------Cohen's d Scale
dtoloadqexc = grep("outlier", #drop outlier files
grep("(alogna|manylabs)_exclude.csv", # only include the _d files for algona/manylabs
grep("qtest_fixed_.*_exclude", list.files(), value=T),
value=T, invert=T),
value=T, invert=T)
dqsex = do.call(rbind, lapply(dtoloadqexc, read.csv)) %>%
mutate(mdh0scale = sqrt(2 * vbar * mdh0 / (k - 1)),
mdh25scale = sqrt(2 * vbar * mdh25 / (k - 1)),
mdh33scale = sqrt(2 * vbar * mdh33 / (k - 1)),
mdh67scale = sqrt(2 * vbar * mdh67 / (k - 1)))
dqsex
write.csv(dqsex, "./aggregate/qtest_exclude_full_d.csv", row.names=F)
write.csv(dqsex %>% select(paper, experiment, p0, p25, p33, p67, mdh0scale, mdh25scale, mdh33scale, mdh67scale),
"./aggregate/table3d_exc.csv")
## Compare inclusion vs. exclusion of original study
dextmp = filter(dqsex, experiment != 'Quote Attribution')
as.character(dextmp$experiment) == dqs$experiment
which(as.integer(dextmp$p0 < .05) != as.integer(dqs$p0 < .05))
which(as.integer(dextmp$p25 < .05) != as.integer(dqs$p25 < .05))
which(as.integer(dextmp$p33 < .05) != as.integer(dqs$p33 < .05))
which(as.integer(dextmp$p67 < .05) != as.integer(dqs$p67 < .05))
dextmp[c(9, 22),]
dqs[c(9, 22),]
# By excluding the original study, we only affect conclusions of hypothesis tests for 2 experiments.
# One of these (Eerland's Intentionality) is because the original study is the outlier.
# For the other (ML's mathartgender) it only affects the test of exact replication.
###--------Natural Scale
toloadqexc = grep("outlier", #drop outlier files
grep("(alogna|manylabs)_exclude_d.csv", # only include the _d files for algona/manylabs
grep("qtest_fixed_.*_exclude", list.files(), value=T),
value=T, invert=T),
value=T, invert=T)
qsex = do.call(rbind, lapply(toloadqexc, read.csv)) %>%
mutate(mdh0scale = sqrt(2 * vbar * mdh0 / (k - 1)),
mdh25scale = sqrt(2 * vbar * mdh25 / (k - 1)),
mdh33scale = sqrt(2 * vbar * mdh33 / (k - 1)),
mdh67scale = sqrt(2 * vbar * mdh67 / (k - 1)))
qsex
write.csv(qsex, "./aggregate/qtest_exclude_full.csv", row.names=F)
###----Compare scales
# qsex$experiment == dqsex$experiment
sum(as.integer(qsex$p0 < .05) != as.integer(dqsex$p0 < .05))
sum(as.integer(qsex$p25 < .05) != as.integer(dqsex$p25 < .05))
sum(as.integer(qsex$p33 < .05) != as.integer(dqsex$p33 < .05))
sum(as.integer(qsex$p67 < .05) != as.integer(dqsex$p67 < .05))
summary(abs(qsex$p0 - dqsex$p0))
summary(abs(qsex$p25 - dqsex$p25))
summary(abs(qsex$p33 - dqsex$p33))
summary(abs(qsex$p67 - dqsex$p67))
# Not sensitive to change in scale.
###----------------------------------------------------------------------###
###----------------------------------------------------------------------###
### Outlier Results
###----------------------------------------------------------------------###
###----------------------------------------------------------------------###
###-------------INCLUDE INITIAL FINDING---------------------------------###
###--------Cohen's d Scale
dtoloadol = grep("outlier", #drop outlier files
grep("(alogna|manylabs)_include_outlier.csv", # only include the _d files for algona/manylabs
grep("qtest_fixed_.*_include", list.files(), value=T),
value=T, invert=T),
value=T)
dol = do.call(rbind, lapply(dtoloadol, read.csv)) %>%
select(paper, experiment, k, outliersite, stdresid, Qi,
p0, p25, p33, p67, tbardot) %>%
left_join(dplyr::select(dqs, paper, experiment, Q)) %>%
select(paper, experiment, outliersite, stdresid, Q, Qi,
p0, p25, p33, p67, tbardot)
# Compare outlier analysis to full analysis on Cohen's d scale
# dol$experiment == dqs$experiment
dp0 = which(as.integer(dol$p0 < .05) != as.integer(dqs$p0 < .05))
dp25 = which(as.integer(dol$p25 < .05) != as.integer(dqs$p25 < .05))
dp33 = which(as.integer(dol$p33 < .05) != as.integer(dqs$p33 < .05))
dp67 = which(as.integer(dol$p67 < .05) != as.integer(dqs$p67 < .05))
dol$diff0 = 0; dol$diff0[dp0] = 1
dol$diff25 = 0; dol$diff25[dp25] = 1
dol$diff33 = 0; dol$diff33[dp33] = 1
dol$diff67 = 0; dol$diff67[dp67] = 1
head(dol, 10)
write.csv(dol, "./aggregate/table4d.csv", row.names=F)
# get only the rows where hypothesis tests change based on one outlier
write.csv(dol %>% slice(unique(c(dp0, dp25, dp33, dp67))),
"./aggregate/outliers_d_diffs.csv", row.names=F)
dol %>% slice(unique(c(dp0, dp25, dp33, dp67)))
# get only the rows where hypothesis tests change based on one outlier
ddifs = dol %>% slice(unique(c(dp0, dp25, dp33, dp67)))
ddifs$Q/ddfs$Qi
# get only the rows where hypothesis tests change based on one outlier
ddifs = dol %>% slice(unique(c(dp0, dp25, dp33, dp67)))
ddifs$Q/ddifs$Qi
(ddifs$Q - ddifs$Qi)/ddifs$Q
mdh_constvar(20, alpha=.05, power=.6)
k = 20; sqrt(2*mdh_constvar(k, alpha=.05, power=.6))
k = 30; sqrt(2*mdh_constvar(k, alpha=.05, power=.6))
k = 30; sqrt(mdh_constvar(k, alpha=.05, power=.6))
k = 30; v=2/60; sqrt(2*v*mdh_constvar(k, alpha=.05, power=.6))
k = 30; v=2/50; sqrt(2*v*mdh_constvar(k, alpha=.05, power=.6))
k = 30; v=2/50; sqrt(2*v*mdh_constvar(k, alpha=.05, power=.6))
2/80
sqrt(2*2/80 / 4)
sqrt(2 * 2/80 / 4)
sqrt(2 * 2/65 / 4)
###-----------------------INCLUDE INITIAL STUDY--------------------------###
# Use Cohen's d scale
###-----Paule-Mandel Estimator
dtolaodvcpm = grep("(alogna|manylabs)_vc_include_PM.csv", grep("include_PM", list.files(), value=T), value=T, invert=T)
dpm = do.call(rbind, lapply(dtolaodvcpm, read.csv)) %>%
left_join(dplyr::select(dqs, paper, experiment, k, p0, p25, p33, p67, vbar)) %>%
select(paper, experiment, k, tau2, cilb=ci.lb, ciub=ci.ub, I2, H2, p0, p25, p33, p67, vbar)
dests = dpm %>%
filter(p33 > .05) # 'replicating studies' are ones who we fail to reject replication for 1/3
nrow(dests)
summary(dests$tau2/dests$vbar)
summary(dests$ciub/dests$vbar)
summary(sqrt(2*dests$tau2))
write.csv(dests, './aggregate/vcs_include_pm.csv', row.names=F)
dests = dpm %>%
filter(p25 > .05) # 'replicating studies' are ones who we fail to reject replication for 1/3
nrow(dests)
summary(dests$tau2/dests$vbar)
summary(dests$ciub/dests$vbar)
summary(sqrt(2*dests$tau2))
write.csv(dests, './aggregate/vcs_include_pm.csv', row.names=F)
dests
sqrt(2 * dests$tau2)
summary(sqrt(2 * dests$tau2))
summary(1/(1/dests$I2 - 1))
1/dests$I2
1/dests$I2 - 1
1/dests$I2
1/(dests$I2/100)
1/(dests$I2/100) - 1
1/(1/(dests$I2/100) - 1)
summary(1/(1/(dests$I2/100) - 1))
summary(sqrt(2 * dests$tau2))
summary(sqrt(2 * dests$tau2))/2
summary(sqrt(2 * dests$tau2))*2
summary((2 * dests$tau2)*2
)
summary((2 * dests$tau2))
summary(dests$tau2) / (2/65)
summary(dests$tau2) / (2/80)
summary(dests$tau2) / (2/75)
summary(dests$tau2) / (2/100)
summary(1/(1/(dests$I2/100) - 1))
summary(dests$tau2/vbar)
summary(dests$tau2/dests$vbar)
